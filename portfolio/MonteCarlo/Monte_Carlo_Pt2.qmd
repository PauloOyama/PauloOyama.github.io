---
title: "Uma vida inteira..."
execute:
  echo: false
---

# Uma breve introdução ao Método de Monte Carlo #2

Agora, que conseguimos entender um pouco do porque ter sido criado e ter visto uma das implementações deste método, veremos também no que se baseia o este método.

## O que sustenta o Método de Monte Carlo?

Explicaremos isso, de uma forma simplicada, pois sua prova é complexa e grande, para tanto nos atrelaremos mais a ideia do "Por que" e menos do "Como". O método de M.C é sustentando pelo teorema da Lei dos Grandes Números (L.G.N ), este teorema tem a seguinte proposta, repita um determinado experimento um número considerável de vezes, pegue o resultado de cada um e faça sua média aritmética, o resultado é o valor esperado(E\[X\]). Existem várias aplicações para a L.G.N, a mostrada por exemplo, no post do Pi é a de Bernoulli, onde somente há duas probabilidades de ser sim ou não.

## Conceito de Esperança (E\[X\]).

Há esperança em probabilidade, tem como ideia de que algo no final ou no limite irá /tenderá para um determinado número, no nosso caso, uma probabilidade, por isso seu nome, sua notação é dita E\[X\].

$$
\lim_{n\to\infty} \frac{X_1+ X_2+X_3+...+ X_n}{n} = E[X]
$$ Imagine que você em um dia com muito tempo começa a jogar uma moeda para cima, a cada lançamento, você conta qual foi o resultado e lança-a novamente. A ideia de esperança se torna fácil de entender neste caso, nas primeiras horas, o número de vezes que caíram cara ou coroa tendem a não ser 1/2 (0.5), ou seja, nas poucas horas que você jogou um número "n" pequeno de vezes, a probabilidade tende para algum lado da moeda. Mas, você, entendiado, continua a jogar a moeda e contar seu resultado, ao fazer isso por um dia inteiro, você verá que o número de vezes que caíram cara e coroa tendem "magicamente" para 1/2, ou seja, ao jogar um número de "n" de vezes muito grande a probabilidade se aproximou de 0.5.

## Explicação matemática

Considere que,

$$
X_i  = \begin{cases} 1,se \space o \space  resultado \space  se \space for \space  cara;\\
                      0,se \space   o  \space resultado \space se \space  for  \space  cara;
        \end{cases}
$$

Logo, como é o jogar de moeda, temos que,

$$
P(X_i = 1) = \frac{1}{2} \space e \space P(X_i = 0) = 1 - \frac{1}{2} = \frac{1}{2}
$$

Assim, pela esperança temos que no limite, $$
E(X) = 0.P(X=0) + 1.P(X=1) = 1.\frac{1}{2} = \frac{1}{2}
$$

Utilizando o código em R com essa lógica geramos o gráfico a seguir, e veja que interessante, o gráfico mostrando a plotagem dos valores se aproximando de $\frac{1}{2}$, conforme o número de lançamentos aumenta.

```{r}
#| fig-keep: last
#| fig-align: center
#lança a moeda 5000 vezes e guarda
# este vetor de tamanho 5 mil na variavel lancamentos
lancamentos <- sample (x=c(0 ,1) , size =5000 , replace = TRUE )

proporcao <- cumsum ( lancamentos )/ 1:5000
#o comando acima calcula a média acumulada para cada
# valor de n entre 1 e 5000 e guarda este vetor de
#médias em proporcao

#os comandos a seguir gerararam a Figura 1
plot (x = 1:5000 , y = proporcao ,type = "l",
xlab = "numero de lancamentos ",
ylab = " proporcao de caras ")
abline (h = c(0.5) , col = "red")
```

Agora, vejamos como isso ocorre em um dado, utilizando os conceitos de esperança. É legal, utilizarmos um dado por que ele se distancia da distribuição de Bernoulli, no qual se aplicar para valores binários, como um dado tem 6 faces, temos 6 possíveis ocorrências de mesma probabilidade cada, saímos das Distribuições de Bernoulli e entramos em Distribuições Uniformes.

Suponha que outro dia de tédio tenha chegado, mas desta vez, curiosamente você ao invés de lançar uma moeda, você está agora lançando dados e outra vez você anota o número da face que caiu para cima. É intrigante pensar, o que teremos como a média de todas as jogadas no final do dia (Esperança)?

## Resolução matemática

Temos que, $$
X_i \in [1,2,..,6]
$$

e que a probabilidade de cair alguma dessas faces em um dado não viciado,

$$
P(X_1 = 1)= \frac{1}{6} \\
P(X_2 = 2)= \frac{1}{6} \\
...\\
P(X_6 = 6)= \frac{1}{6} \\
$$ Portanto, na esperança,

$$
E[X] = \frac{1*P(X_1=1)+2*P(X_2=2)+...+6*P(X_6=6)}{6}\\
E[X] = \frac{\frac{1}{6} +\frac{2}{6} +...+ \frac{6}{6} + }{6}\\
$$ \## Utilizando o código em R

Veja, como fica a aproximação,

```{r}
#| fig-keep: last
#| fig-align: center

res <- c()
for(i in 1:10000){
  x <- sample(c(1,2,3,4,5,6),1)
  res[i] <- x 
}
proporcao <- cumsum ( res )/ 1:10000
#Plota Figura 2
plot (x = 1:10000 , y = proporcao ,type = "l", ylab = "Media", xlab = "Numero de Lancamentos")
abline (h = c(3.5) , col = "red")
```

## Expansão: Uma vida inteira de lançamentos.

Imagine agora, que ao invés de um dia entendiante, uma determinada pessoa faça isso por toda a sua vida, e no final de cada dia, depois de fazer todos os lançamentos do dia pega cada média final de cada dia e a escreve em um caderno, como seriam dadas as distribuição das médias de cada dia?

```{r}
#| fig-keep: last
#| fig-align: center
res <- c()
dist <-c()
#For representando os 1000 dias da sua vida
for(j in 1:1000){
 #10000 lancamentos sao feitos a cada dia
  for(i in 1:10000){
    x <- sample(c(1,2,3,4,5,6),1)
    res[i] <- x 
  }
# ao final de cada dia anota no caderno "dist"
 dist[j] <- mean(res)
}
hist(dist)
```

Veja que interessante,

No final de sua vida, a chance da média diaria de lancamentos ter sido de 3.5 é maior do por exemplo 3.56 ou 3.46, ou seja, em um vida inteira, a chance maior é de que a média dos lançamentos diários fiquem por volta de 3.49\~3.51, e quase nunca em sua vida um lançamento diário ficou por volta de 3.56 ou 3.46.

## Referências:

-   Código e explicação usados em aula do professor Pedro Franklin da UFU
